{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4486396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b23131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos\n",
    "BASE_DIR = r\"C:\\Users\\thiag\\OneDrive\\Área de Trabalho\\TCC 2\\Scripts\\Arquivos Brutos\"\n",
    "PATH_BOMBEIROS = os.path.join(BASE_DIR, \"BOMBEIROS\")\n",
    "PATH_CIMEHGO = os.path.join(BASE_DIR, \"CIMEHGO\")\n",
    "PATH_INMET = os.path.join(BASE_DIR, \"INMET_GOIANIA\")\n",
    "PATH_RELATOS = os.path.join(BASE_DIR, \"RELATOS\")\n",
    "PATH_EXPORT = r\"C:\\Users\\thiag\\OneDrive\\Área de Trabalho\\TCC 2\\Scripts\\Arquivos Processados\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e9b3d",
   "metadata": {},
   "source": [
    "# Bombeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5bf2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_bombeiros():\n",
    "    colunas = [\"N° DA OCORRÊNCIA\", \"Data\", \"ANO\", \"BAIRRO\", \"ESTADO\", \"ENDEREÇO\", \"FAIXA_ETARIA\", \"SEXO\"]\n",
    "    colunas_upper = [c.upper() for c in colunas]\n",
    "\n",
    "    arquivos = [f for f in os.listdir(PATH_BOMBEIROS) if f.lower().endswith((\".csv\", \".xlsx\"))]\n",
    "    dfs = []\n",
    "\n",
    "    for arquivo in arquivos:\n",
    "        caminho = os.path.join(PATH_BOMBEIROS, arquivo)\n",
    "        if arquivo.lower().endswith(\".csv\"):\n",
    "            df = pd.read_csv(caminho, sep=\";\", encoding=\"latin1\", engine=\"python\")\n",
    "        else:\n",
    "            df = pd.read_excel(caminho)\n",
    "\n",
    "        # normaliza os nomes das colunas\n",
    "        df.columns = [c.strip().upper() for c in df.columns]\n",
    "\n",
    "        # filtra apenas as colunas existentes\n",
    "        colunas_existentes = [c for c in colunas_upper if c in df.columns]\n",
    "        df_filtrado = df[colunas_existentes].copy()\n",
    "\n",
    "        dfs.append(df_filtrado)\n",
    "\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # salva em Excel\n",
    "    caminho_saida = os.path.join(PATH_EXPORT, \"BOMBEIROS_TRATADO.xlsx\")\n",
    "    df_final.to_excel(caminho_saida, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d85bc",
   "metadata": {},
   "source": [
    "# CIMEHGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9248125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_cimehgo():\n",
    "    colunas = [\"Estação\", \"Data/Hora(Local)\", \"Chuva(mm)\", \"ChuvaAcum.(mm)\"]\n",
    "    arquivos = [f for f in os.listdir(PATH_CIMEHGO) if f.lower().endswith((\".csv\", \".xlsx\"))]\n",
    "\n",
    "    dfs = []\n",
    "    for arquivo in arquivos:\n",
    "        caminho = os.path.join(PATH_CIMEHGO, arquivo)\n",
    "        if arquivo.endswith(\".csv\"):\n",
    "            df = pd.read_csv(caminho, sep=\";\", encoding=\"latin1\", engine=\"python\", skiprows=1)\n",
    "        else:\n",
    "            df = pd.read_excel(caminho)\n",
    "            \n",
    "            \n",
    "        df = df[colunas]\n",
    "        dfs.append(df)\n",
    "        #df.columns = df.columns.str.strip()  # remove espaços extras\n",
    "        #df = df[[c for c in colunas if c in df.columns]]  # seleciona apenas colunas existentes\n",
    "        #dfs.append(df)\n",
    "\n",
    "    if dfs:\n",
    "        df_final = pd.concat(dfs, ignore_index=True)\n",
    "        #df_final.to_csv(os.path.join(PATH_EXPORT, \"CIMEHGO_TRATADO.csv\"), index=False, sep=\";\", encoding=\"latin1\")\n",
    "        df_final.to_excel(os.path.join(PATH_EXPORT, \"CIMEHGO_TRATADO.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5859da",
   "metadata": {},
   "source": [
    "# INMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4defbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_inmet():\n",
    "    tabelas = []\n",
    "\n",
    "    for arquivo in os.listdir(PATH_INMET):\n",
    "        if arquivo.lower().endswith((\".csv\", \".xlsx\", \".xls\")):\n",
    "            caminho = os.path.join(PATH_INMET, arquivo)\n",
    "            print(f\"Lendo: {arquivo}\")\n",
    "\n",
    "            if arquivo.lower().endswith(\".csv\"):\n",
    "                df = pd.read_csv(caminho, sep=\";\", encoding=\"latin1\", engine=\"python\")\n",
    "            else:\n",
    "                df = pd.read_excel(caminho)\n",
    "\n",
    "            tabelas.append(df)\n",
    "\n",
    "    if not tabelas:\n",
    "        print(\"Nenhum arquivo INMET encontrado!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenar arquivos diretamente\n",
    "    df_inmet = pd.concat(tabelas, ignore_index=True)\n",
    "\n",
    "    # Renomear coluna de precipitação se existir\n",
    "    if \"PRECIPITAÇÃO TOTAL, HORÁRIO (mm)\" in df_inmet.columns:\n",
    "        df_inmet.rename(columns={\"PRECIPITAÇÃO TOTAL, HORÁRIO (mm)\": \"Chuva(mm)\"}, inplace=True)\n",
    "\n",
    "    # Extrair informações da coluna INFO se existir\n",
    "    if \"INFO\" in df_inmet.columns:\n",
    "        def extrair_info(pattern, texto):\n",
    "            match = re.search(pattern, str(texto))\n",
    "            return match.group(1).strip() if match else None\n",
    "\n",
    "        df_inmet[\"ESTACAO\"] = df_inmet[\"INFO\"].apply(lambda x: extrair_info(r\"ESTACAO:;([^/]+)\", x))\n",
    "        df_inmet[\"LATITUDE\"] = df_inmet[\"INFO\"].apply(lambda x: extrair_info(r\"LATITUDE:;([-\\d,.]+)\", x))\n",
    "        df_inmet[\"LONGITUDE\"] = df_inmet[\"INFO\"].apply(lambda x: extrair_info(r\"LONGITUDE:;([-\\d,.]+)\", x))\n",
    "\n",
    "        df_inmet[\"LATITUDE\"] = df_inmet[\"LATITUDE\"].str.replace(\",\", \".\", regex=False).astype(float)\n",
    "        df_inmet[\"LONGITUDE\"] = df_inmet[\"LONGITUDE\"].str.replace(\",\", \".\", regex=False).astype(float)\n",
    "\n",
    "\n",
    "    def converter_hora_utc(hora_utc):\n",
    "        if pd.isna(hora_utc):\n",
    "            return None\n",
    "        # transformar em string e remover 'UTC' e espaços\n",
    "        hora_str = str(hora_utc).replace(\"UTC\", \"\").strip()\n",
    "        # preencher com zeros à esquerda para garantir 4 dígitos\n",
    "        hora_str = hora_str.zfill(4)\n",
    "        hh = hora_str[:2]\n",
    "        mm = hora_str[2:]\n",
    "        return f\"{hh}:{mm}\"\n",
    "\n",
    "    # aplicar ao DataFrame\n",
    "    df_inmet[\"Hora\"] = df_inmet[\"Hora UTC\"].apply(converter_hora_utc)\n",
    "    \n",
    "    # Selecionar colunas finais de forma segura\n",
    "    c_final = [\"Data\", \"Hora\", \"DataHora\", \"Chuva(mm)\", \"LATITUDE\", \"LONGITUDE\", \"ESTACAO\"]\n",
    "    df_inmet = df_inmet.reindex(columns=c_final)\n",
    "\n",
    "    # Salvar arquivo final\n",
    "    #saida = os.path.join(PATH_EXPORT, \"INMET_COMBINADO.csv\")\n",
    "    saida = os.path.join(PATH_EXPORT, \"INMET_COMBINADO.xlsx\")\n",
    "    #df_inmet.to_csv(saida, sep=\",\", index=False, encoding=\"latin1\")\n",
    "    df_inmet.to_excel(saida)\n",
    "\n",
    "    return df_inmet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfd384",
   "metadata": {},
   "source": [
    "# RELATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9b4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_relatos():\n",
    "    arquivos = [f for f in os.listdir(PATH_RELATOS) if f.lower().endswith((\".csv\", \".xlsx\"))]\n",
    "\n",
    "    if len(arquivos) <= 1:\n",
    "        return\n",
    "\n",
    "    dfs = []\n",
    "    for arquivo in arquivos:\n",
    "        caminho = os.path.join(PATH_RELATOS, arquivo)\n",
    "        if arquivo.endswith(\".csv\"):\n",
    "            df = pd.read_csv(caminho, sep=\";\", encoding=\"latin1\", engine=\"python\")\n",
    "        else:\n",
    "            df = pd.read_excel(caminho)\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "    df_final.to_csv(os.path.join(PATH_EXPORT, \"RELATOS_TRATADO.csv\"), index=False, sep=\";\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc99456",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f19067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fujioka\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo: INMET_GOIANIA_01-01-2020_A_31-12-2020.xlsx\n",
      "Lendo: INMET_GOIANIA_01-01-2021_A_31-12-2021.xlsx\n",
      "Lendo: INMET_GOIANIA_01-01-2022_A_31-12-2022.xlsx\n",
      "Lendo: INMET_GOIANIA_01-01-2023_A_31-12-2023.xlsx\n",
      "Lendo: INMET_GOIANIA_01-01-2024_A_31-12-2024.xlsx\n",
      "Lendo: INMET_GOIANIA_01-01-2025_A_30-09-2025.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    processar_bombeiros()\n",
    "    processar_cimehgo()\n",
    "    processar_inmet()\n",
    "    processar_relatos()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
